{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3773f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install factor_analyzer\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, homogeneity_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score, auc, f1_score, accuracy_score, recall_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import process_time\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfbaab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(df, target = 'fraud_bool'):\n",
    "    # split df to train set and test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
    "                                                        train_size = 0.8, random_state=0)\n",
    "    \n",
    "    \n",
    "    # split train set to train set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify = y_train, \n",
    "                                                    train_size = 0.8, random_state=0)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "def train_valid_test_split2(df, target = 'Segmentation'):\n",
    "    # split df to train set and test set\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n",
    "                                                        train_size = 0.8, random_state=0)\n",
    "    \n",
    "    \n",
    "    # split train set to train set and validation set\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify = y_train, \n",
    "                                                    train_size = 0.8, random_state=0)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85a26c",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn impute numeric columns and one hot encode category columns\n",
    "def ohe(X_train, X_valid, X_test):\n",
    "    # impute numeric columns\n",
    "    numcols = X_train.select_dtypes(include=['float','int']).columns\n",
    "    imputer = KNNImputer(n_neighbors=3, weights=\"uniform\")\n",
    "    imputer.fit(X_train[numcols])\n",
    "    X_train[numcols] = pd.DataFrame(imputer.transform(X_train[numcols]), columns=numcols)\n",
    "    X_valid[numcols] = pd.DataFrame(imputer.transform(X_train[numcols]), columns=numcols)\n",
    "    X_test[numcols] = pd.DataFrame(imputer.transform(X_train[numcols]), columns=numcols)\n",
    "    \n",
    "    # impute categorical columns\n",
    "    ohe_training_predictors = pd.get_dummies(X_train)\n",
    "    ohe_valid_predictors = pd.get_dummies(X_valid)\n",
    "    ohe_test_predictors = pd.get_dummies(X_test)\n",
    "    X_train, X_valid = ohe_training_predictors.align(\n",
    "        ohe_valid_predictors,join='left', axis=1)\n",
    "\n",
    "    X_train, X_test = ohe_training_predictors.align(\n",
    "        ohe_test_predictors,join='left', axis=1)\n",
    "    \n",
    "    X_train=X_train.fillna(0)\n",
    "    X_valid=X_valid.fillna(0)\n",
    "    X_test=X_test.fillna(0)\n",
    "    \n",
    "    return X_train, X_valid, X_test\n",
    "\n",
    "# X_train, X_valid, X_test = ohe(X_train, X_valid, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f82343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_scale(X_train, X_valid, X_test):\n",
    "    sc = StandardScaler()\n",
    "    fit = sc.fit(X_train)\n",
    "    cols = X_train.columns\n",
    "    X_train = pd.DataFrame(fit.transform(X_train),columns=cols)\n",
    "    X_valid = pd.DataFrame(fit.transform(X_valid),columns=cols)\n",
    "    X_test = pd.DataFrame(fit.transform(X_test),columns=cols)\n",
    "    \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_catcols(X_train, X_valid, X_test):\n",
    "    catcols = X_train.select_dtypes(include=['object']).columns\n",
    "    X_train.drop(columns = catcols, inplace=True)\n",
    "    X_valid.drop(columns = catcols, inplace=True)\n",
    "    X_test.drop(columns = catcols, inplace=True)\n",
    "    \n",
    "    return X_train, X_valid, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23229984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(X_train, y_train):\n",
    "    # over-sampling: match the minority class to the majority class\n",
    "    from collections import Counter\n",
    "    from imblearn.over_sampling import (RandomOverSampler, SMOTE, ADASYN)\n",
    "    sampler = RandomOverSampler(sampling_strategy='auto',random_state=0)\n",
    "    X_train_rs, y_train_rs = sampler.fit_resample(X_train, y_train)\n",
    "#     print('Before resample {}'.format(Counter(y_train)),' RandomOverSampler {}'.format(Counter(y_train_rs)))\n",
    "    \n",
    "    return X_train_rs, y_train_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6919bd",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, X_train, y_train, X_valid, y_valid):\n",
    "    t_start = process_time()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # predict\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_valid)\n",
    "    t_stop = process_time()\n",
    "    t = t_stop - t_start\n",
    "    \n",
    "    # calculate score\n",
    "    from sklearn.metrics import roc_curve,roc_auc_score, auc, f1_score, accuracy_score, recall_score\n",
    "    train_roc = roc_auc_score(y_train,train_pred)\n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    test_roc = roc_auc_score(y_valid,test_pred)\n",
    "    f1_score = f1_score(y_valid, test_pred, average='weighted')\n",
    "    acc = accuracy_score(y_valid, test_pred)\n",
    "    recall_score = recall_score(y_valid, test_pred, average='weighted')\n",
    "    \n",
    "    perf = pd.DataFrame({'acc':[round(acc,3)],\n",
    "                         'cv_score':[round(mean(cv_score),3)],\n",
    "                         'train_roc':[round(train_roc,3)],                \n",
    "                         'test_roc':[round(test_roc,3)],\n",
    "                         'recall_score':[round(recall_score,3)],\n",
    "                         'f1_score':[round(f1_score,3)],\n",
    "                         'run_time':[round(t,5)]\n",
    "                        })\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76150de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(model, X_train, y_train, X_valid, y_valid):\n",
    "    t_start = process_time()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    # predict\n",
    "    train_pred = pd.DataFrame(model.predict(X_train))\n",
    "    test_pred = pd.DataFrame(model.predict(X_valid))\n",
    "    train_pred_prob = model.predict_proba(X_train)\n",
    "    test_pred_prob = model.predict_proba(X_valid)\n",
    "    t_stop = process_time()\n",
    "    t = t_stop - t_start\n",
    "    # calculate score\n",
    "    from sklearn.metrics import roc_curve,roc_auc_score, auc, f1_score, accuracy_score, recall_score\n",
    "    train_roc = roc_auc_score(y_train,train_pred_prob, multi_class = 'ovr', average = 'weighted')\n",
    "    cv_score = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    test_roc = roc_auc_score(y_valid,test_pred_prob, multi_class = 'ovr', average = 'weighted')\n",
    "    f1_score = f1_score(y_valid, test_pred, average='weighted')\n",
    "    acc = accuracy_score(y_valid, test_pred)\n",
    "    recall_score = recall_score(y_valid, test_pred, average='weighted')\n",
    "    \n",
    "    perf = pd.DataFrame({'acc':[round(acc,3)],\n",
    "                         'cv_score':[round(mean(cv_score),3)],\n",
    "                         'train_roc':[round(train_roc,3)],                \n",
    "                         'test_roc':[round(test_roc,3)],\n",
    "                         'recall_score':[round(recall_score,3)],\n",
    "                         'f1_score':[round(f1_score,3)],\n",
    "                         'run_time':[round(t,3)]\n",
    "                        })\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132c851",
   "metadata": {},
   "source": [
    "# Graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74695826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve_graph(perf_out):\n",
    "    plt.plot(perf_out['train_ratio'], perf_out['recall_score'], label = \"recall_score\")\n",
    "    plt.plot(perf_out['train_ratio'], perf_out['train_roc'], label = \"train_roc\")\n",
    "    plt.plot(perf_out['train_ratio'], perf_out['test_roc'], label = \"test_roc\")\n",
    "    plt.plot(perf_out['train_ratio'], perf_out['f1_score'], label = \"f1_score\")\n",
    "    # plt.plot(le_perf_out['train_ratio'], perf_out['run_time'], label = \"run_time\")\n",
    "    plt.xlabel(\"train data size\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dc1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_graph(clf, X_train):\n",
    "    importances = pd.DataFrame({'features': X_train.columns, 'importance': np.round(clf.feature_importances_,3)})\n",
    "    importances = importances.sort_values('importance',ascending=False)\n",
    "    importances.sort_values('importance', ascending=False)\n",
    "    import seaborn as sns\n",
    "    sns.set(rc={'figure.figsize':(25,15)})\n",
    "    sns.barplot(x='importance', y = 'features', data = importances[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65ef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_graph(clf, X_train, y_train):\n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    clf.fit\n",
    "    _ = tree.plot_tree(clf, \n",
    "                       feature_names=X_train.columns,  \n",
    "                       class_names=y_train.unique().astype(str),\n",
    "                       filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans(X_train):\n",
    "    silhouette_scores = []\n",
    "    inertia_scores = []\n",
    "\n",
    "    # Loop through each k value \n",
    "    k_range = range(1, 10)\n",
    "    for k in k_range:\n",
    "        model = KMeans(n_clusters=k, random_state=0)\n",
    "        cluster_labels = model.fit_predict(X_train)\n",
    "    #     silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "        inertia = model.inertia_\n",
    "    #     silhouette_scores.append(silhouette_avg)\n",
    "        inertia_scores.append(inertia)\n",
    "\n",
    "    k_range2 = range(2, 10)\n",
    "    for k in k_range2:\n",
    "        model = KMeans(n_clusters=k, random_state=0)\n",
    "        cluster_labels = model.fit_predict(X_train)\n",
    "        silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "    #     inertia = model.inertia_\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "    #     inertia_scores.append(inertia)\n",
    "\n",
    "    # Plot the scores for each k value\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    color = 'blue'\n",
    "    ax1.set_xlabel('Number of clusters')\n",
    "    ax1.set_ylabel('Silhouette Score', color=color)\n",
    "    ax1.plot(k_range2, silhouette_scores, label='Silhouette Score', color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'red'\n",
    "    ax2.set_ylabel('SSE', color=color)\n",
    "    ax2.plot(k_range, inertia_scores, label='SSE', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b5d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_label(cluster_labels, label):\n",
    "    cl_op = pd.DataFrame({'label':label, 'cluster':cluster_labels})\n",
    "    op = cl_op.groupby('cluster')['label'].value_counts().unstack(fill_value=0)\n",
    "    print(op)\n",
    "    ax = op.plot(kind='bar', stacked=True, color=['blue', 'red', 'orange','green', 'black', 'yellow',  'pink'])\n",
    "    ax.set_xlabel('cluster result')\n",
    "    ax.set_ylabel('label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb730ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_em(X_train):\n",
    "    silhouette_scores = []\n",
    "    k_range2 = range(2, 8)\n",
    "    for k in k_range2:\n",
    "        model = GaussianMixture(n_components=k).fit(X_train)\n",
    "        cluster_labels = model.fit_predict(X_train)\n",
    "        silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "    #     inertia = model.inertia_\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "    color = 'blue'\n",
    "    ax1.set_xlabel('Number of clusters')\n",
    "    ax1.set_ylabel('Silhouette Score', color=color)\n",
    "    ax1.plot(k_range2, silhouette_scores, label='Silhouette Score', color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    ax1.legend(loc='lower left')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e4c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
